# ğŸ“š Paper Reading List

This is a collection of papers and related topics for research.

## ğŸŒŸ Topics

1. **âš¡ Transformer**
   - [Attention Is All You Need ~ 2017 NeurIPS](https://arxiv.org/abs/1706.03762) ğŸ“„
3. **ğŸ” LLM**
4. **ğŸ› ï¸ PEFT** (Parameter-Efficient Fine-Tuning)
5. **ğŸ”§ Model Optimization**
   - [Distilling the Knowledge in a Neural Network ~ 2014 NeurIPS](https://arxiv.org/abs/1503.02531) ğŸ“„
   - [LLM Pruning and Distillation in Practice: The Minitron Approach ~ 2024 NVIDIA](https://arxiv.org/abs/2408.11796) ğŸ“„
   
6. **ğŸ”’ LLM Security**
   - [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226) ğŸ“„
7. **ğŸš€ Tasks**
   - ğŸ“ Summarization
       - [GSum: A General Framework for Guided Neural Abstractive Summarization ~ 2021 NAACL](https://arxiv.org/abs/2010.08014) ğŸ“„
   - ğŸŒ Translation
   - ğŸ” NER (Named Entity Recognition)
   - And more...
